{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhecan/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/zhecan/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "train = pd.read_csv('../../data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../../data/test.tsv', sep='\\t')\n",
    "train.shape\n",
    "amount = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "def extract_verbs_and_adj(phrase):\n",
    "    words = []\n",
    "    \n",
    "    tags = TextBlob(phrase).tags\n",
    "    for tag in tags:\n",
    "        if tag[1][:2] == \"VB\" or tag[1][:2] == \"JJ\":\n",
    "            words.append(tag[0])\n",
    "    return words\n",
    "\n",
    "def looping_extract_verbs_and_adj(data_set):\n",
    "    phrases_vb_adj = []\n",
    "\n",
    "    for (index, phrase) in enumerate(data_set):\n",
    "        if index % 10 == 0:\n",
    "            print index\n",
    "        phrases_vb_adj.append(' '.join(extract_verbs_and_adj(phrase)))\n",
    "    return phrases_vb_adj\n",
    "\n",
    "train_phrases_vb_adj = looping_extract_verbs_and_adj(train.Phrase[:amount])\n",
    "test_phrases_vb_adj = looping_extract_verbs_and_adj(test.Phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_vb_adj_sentiment(phrases_vb_adj):\n",
    "    v2 = CountVectorizer(ngram_range=(0, 4),  min_df=2, max_df=0.95, max_features=1000)\n",
    "    X2 = v2.fit_transform(phrases_vb_adj)\n",
    "    print X2.shape\n",
    "\n",
    "    sentiments = []\n",
    "    for feature in v2.get_feature_names():\n",
    "        sentiment = TextBlob(feature).sentiment\n",
    "        value = sentiment.polarity * sentiment.subjectivity\n",
    "        sentiments.append(value)\n",
    "\n",
    "    print v2.get_feature_names()\n",
    "    print sentiments\n",
    "\n",
    "    from scipy.sparse import csr_matrix\n",
    "\n",
    "    X3 = csr_matrix(X2.shape)\n",
    "    for index in range(X2.shape[0]):\n",
    "        row = X2[index]\n",
    "        for col in range(row.shape[1]):\n",
    "            X3[index, col] = X2[index, col] * sentiments[col]\n",
    "\n",
    "    from scipy.sparse import hstack\n",
    "    X4 = hstack([X1[:amount], X3])\n",
    "    print X4.shape\n",
    "    return X4\n",
    "\n",
    "X_train = add_vb_adj_sentiment(train_phrases_vb_adj)\n",
    "X_test = add_vb_adj_sentiment(test_phrases_vb_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train, train.Sentiment, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_train_train, y_train_train) \n",
    "\n",
    "y_train_test_predict = clf.predict(X_train_test)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "\n",
    "train_output = pd.DataFrame({\n",
    "    'PhraseId': train.PhraseId,\n",
    "    'Phrase':  train_lemma_phrase\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "test_output = pd.DataFrame({\n",
    "    'PhraseId': test.PhraseId,\n",
    "    'Phrase':  test_lemma_phrase\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
