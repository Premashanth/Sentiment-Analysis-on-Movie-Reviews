{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ensemble\n",
    "\n",
    "For the grand finale, let's assemble all of our models into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaac/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all Model Predictions\n",
    "\n",
    "Here we'll load all of the predicted sentiments from each of our individual models. We can then input these predictions as features into a final learner. Hopefully our previous predictions have enough diversity to score well as a team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../../data/test.tsv', sep='\\t')\n",
    "\n",
    "lda_train = pd.read_csv('../latent-dirichlet-allocation/results_train.csv')\n",
    "w2v_train = pd.read_csv('../word-2-vector/results_train.csv')\n",
    "sent_train = pd.read_csv('../sentiment/results_train.csv')\n",
    "# bow_train = pd.read_csv('../bag-of-words/results_train.csv')\n",
    "# pos_train = pd.read_csv('../parts-of-speech/results_train.csv')\n",
    "\n",
    "X_train = pd.DataFrame({\n",
    "    'lda': lda_train.Predicted,\n",
    "    'w2v': w2v_train.Predicted,\n",
    "    'sent': sent_train.Predicted,  \n",
    "#     'bow': bow_train.Sentiment\n",
    "})\n",
    "y_train = sent_train.Sentiment\n",
    "\n",
    "lda_test = pd.read_csv('../latent-dirichlet-allocation/results_test.csv')\n",
    "w2v_test = pd.read_csv('../word-2-vector/results_test.csv')\n",
    "sent_test = pd.read_csv('../sentiment/results_test.csv')\n",
    "# bow_test = pd.read_csv('../bag-of-words/results_test.csv')\n",
    "# pos_test = pd.read_csv('../parts-of-speech/results_test.csv')\n",
    "\n",
    "X_test = pd.DataFrame({\n",
    "    'lda': lda_test.Sentiment,\n",
    "    'w2v': w2v_test.Sentiment,\n",
    "    'sent': sent_test.Sentiment,\n",
    "#     'bow': bow_test.Sentiment\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding on a Learner and Model Representation\n",
    "\n",
    "In order to decide which learner and model to use, we will do some cross validation. The input features are all in the form of sentiment predictions (0-4). Probably the best way to use this data is to take a weighted average of each model's predictions. As a result, I predict that the models based on trees will not do as well as the others such as logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regrssion cross validation runnning...\n",
      "Logistic Regression Score: 0.80\n",
      "dt: 0.010617\n",
      "\n",
      "Random Forest cross validation runnning...\n",
      "Random Forest Score: 0.75\n",
      "dt: 0.219761\n",
      "\n",
      "AdaBoost cross validation runnning...\n",
      "AdaBoost Score:      0.81\n",
      "dt: 0.198987\n",
      "\n",
      "SVC cross validation runnning...\n",
      "SVC Score:           0.80\n",
      "dt: 0.007176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cv(X, y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=50)\n",
    "    boost = AdaBoostClassifier()\n",
    "    svc = SVC()\n",
    "    log = LogisticRegression()\n",
    "\n",
    "    from sklearn.cross_validation import cross_val_score\n",
    "    import time\n",
    "    \n",
    "    t0 = time.time()\n",
    "    print \"Logistic Regrssion cross validation runnning...\"\n",
    "    log_score = cross_val_score(log, X, y).mean()\n",
    "    print \"Logistic Regression Score: %2.2f\" % log_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"Random Forest cross validation runnning...\"\n",
    "    forest_score = cross_val_score(forest, X, y).mean()\n",
    "    print \"Random Forest Score: %2.2f\" % forest_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"AdaBoost cross validation runnning...\"\n",
    "    boost_score = cross_val_score(boost, X, y).mean()\n",
    "    print \"AdaBoost Score:      %2.2f\" % boost_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"SVC cross validation runnning...\"\n",
    "    svc_score = cross_val_score(svc, X, y).mean()\n",
    "    print \"SVC Score:           %2.2f\" % svc_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "    \n",
    "cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like SVC works pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "print \"training svc...\"\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print \"predicting...\"\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'PhraseId': test.PhraseId,\n",
    "    'Sentiment': y_pred\n",
    "})\n",
    "results.to_csv('results.csv', index=False)\n",
    "\n",
    "print 'done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Results\n",
    "\n",
    "![Kaggle Results]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's take a step back and inspect the data we are learning from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How neutral is our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent LDA Neutrality: 0.315263\n",
      "Percent Word2Vec Neutrality: 78.441625\n",
      "Percent Sentiment Neutrality: 82.054338\n"
     ]
    }
   ],
   "source": [
    "print \"Percent LDA Neutrality: %f\" % sum(100 * (X_train.lda == 2) / len(X_train))\n",
    "print \"Percent Word2Vec Neutrality: %f\" % sum(100 * (X_train.w2v == 2) / len(X_train))\n",
    "print \"Percent Sentiment Neutrality: %f\" % sum(100 * (X_train.sent == 2) / len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How diverse is our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Similarity: 70.762527\n"
     ]
    }
   ],
   "source": [
    "all_same_predictions = (X_train.w2v == X_train.sent) & (X_train.w2v == X_train.lda)\n",
    "print \"Percent Similarity: %f\" % (100 * sum(all_same_predictions) / float(len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often do each of the models predict the true sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent LDA is correct: 0.202486\n",
      "Percent Sentiment is correct: 54.218890\n",
      "Percent Word2Vec is correct: 54.204793\n"
     ]
    }
   ],
   "source": [
    "print \"Percent LDA is correct: %f\" % (100 * sum((X_train.lda == y_train)) / float(len(X_train)))\n",
    "print \"Percent Sentiment is correct: %f\" % (100 * sum((X_train.sent == y_train)) / float(len(X_train)))\n",
    "print \"Percent Word2Vec is correct: %f\" % (100 * sum((X_train.w2v == y_train)) / float(len(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often do any of the models predict the true sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent any model is correct: 64.203511\n"
     ]
    }
   ],
   "source": [
    "any_correct = (X_train.lda == y_train) | (X_train.sent == y_train) | (X_train.w2v == y_train)\n",
    "print \"Percent any model is correct: %f\" % (100 * sum(any_correct) / float(len(X_train)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
