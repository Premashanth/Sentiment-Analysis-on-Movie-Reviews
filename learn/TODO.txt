TODO

1. positions of words in sentence
2. part of speech tagging
3. remove 95 percent frequent words and words show up only once
4. LTD
5. Porter Stemming and Lemmatizing



6. train word2vec with larger texts
7. part of speech
8. lemmas
9. assemble models





pipeline = Pipeline([
    ('bow', CountVectorizer(analyzer=split_into_lemmas)),  # strings to token integer counts
    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores
    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier
])