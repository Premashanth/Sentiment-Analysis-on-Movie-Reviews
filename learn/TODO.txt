TODO

1. positions of words in sentence
2. part of speech tagging
3. remove 95 percent frequent words and words show up only once
4. LDA
5. Porter Stemming and Lemmatizing



6. train word2vec with larger texts
7. part of speech/ pos - sentiment average of noun, vb, adj, combined every two words of vb, adj

8. lemmas
9. assemble models


 Stemmed, Porter Stemming




pipeline = Pipeline([
    ('bow', CountVectorizer(analyzer=split_into_lemmas)),  # strings to token integer counts
    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores
    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier
])


analyze:

1. analyze textblob different libraries for sentiments, compare with real ones
2. analyze different ensemble models
