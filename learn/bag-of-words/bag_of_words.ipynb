{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "In this notebook, I'll be attempting to predict movie review sentiments using a bag of words model. This model does not look at the context of words in reviews, only their presence and frequency. Hopefully, by classifying reviews based on features corresponding to the frequency of each word will yield somewhat accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('../../data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../../data/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorization\n",
    "\n",
    "Our first attempt at feature extraction will be using the [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) from [scikit-learn](http://scikit-learn.org/stable/index.html). This tool will look at each review and count the number of times each word occurs. The number of times a word appears in a review will hopefully correlate with the sentiment of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "subset = train[:50000]\n",
    "\n",
    "# Create the vectorizer\n",
    "# We ignoring common english words and only look at a maximum of 2000 unique words\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=3000)\n",
    "X = vectorizer.fit_transform(subset.Phrase).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "Now that we've extracted our features, we can learn from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500)\n",
    "boost = AdaBoostClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import time\n",
    "\n",
    "# t0 = time.time()\n",
    "# forest_score = cross_val_score(forest, X, train.Sentiment).mean()\n",
    "# print \"Random Forest: %2.2f\" % forest_score\n",
    "# print \"dt: %f\" % (time.time() - t0)\n",
    "\n",
    "# t0 = time.time()\n",
    "# boost_score = cross_val_score(boost, X, train.Sentiment).mean()\n",
    "# print \"AdaBoost:      %2.2f\" % boost_score\n",
    "# print \"dt: %f\" % (time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "svc_score = cross_val_score(svc, X, subset.Sentiment).mean()\n",
    "print \"SVC:           %2.2f\" % svc_score\n",
    "print \"dt: %f\" % (time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
