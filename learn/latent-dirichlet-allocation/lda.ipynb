{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation (LDA) is a model that is able to group similar data together. This will reduce the dimensionality of our data by grouping similar words together. For example, the words **movie**, **film**, and **show** might be grouped into one topic called **MOVIE_related**. Putting synonyms into one feature instead of numerous greatly reduces the dimensionality of our data. Hopefully this will improve our learner's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('../../data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('../../data/test.tsv', sep='\\t')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization\n",
    "\n",
    "Now that the data is loaded, we can vectorize it using the Count vectorizer. This will give us a matrix of word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 14933)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "subset = train\n",
    "\n",
    "# Create the vectorizer\n",
    "# We ignoring common english words and only look at a maximum of 2000 unique words\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=2, max_df=0.95)\n",
    "X = vectorizer.fit_transform(subset.Phrase)\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Dimension Reduction\n",
    "\n",
    "Now we can put LDA to use and reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 10)\n",
      "dt: 239.463410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=10)\n",
    "\n",
    "t0 = time.time()\n",
    "L = lda.fit_transform(X, subset.Sentiment)\n",
    "print L.shape\n",
    "print \"dt: %f\" % (time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "movie story new love hollywood seen cinema entertaining kids dark star feels ca history compelling sweet actually ultimately fascinating culture tv amusing gives romance minute simply ending middle project likely despite particularly eye honest budget getting pace moment reality kid issues mood certainly game comedies york dry air tell terrific\n",
      "Topic #1:\n",
      "does way director world character drama performance thriller special half care hour feature nearly modern screenplay clever narrative camera title debut live french instead probably leave fine believe viewers impossible room production quality michael writing city final pop animation process boring ii spy turns latest acted mean mess tension fiction\n",
      "Topic #2:\n",
      "good little humor really sense performances fun kind end picture high video works comes women entertainment want dull pretty say cinematic filmmakers quirky goes school summer worst ways head surprisingly laugh solid act reason stuff left concept satisfying attention cut got ride forced intriguing america having loud ugly plenty clear\n",
      "Topic #3:\n",
      "time comedy movies people man hard watch things years quite times romantic did day bit gets moving know horror smart portrait powerful tone spirit dramatic cold working dead deeply eyes teen personal cheap easily bland strange oscar career welcome guy sequel monster pretentious inspired elements skin try sadness mediocre word\n",
      "Topic #4:\n",
      "bad old action films family young dialogue scenes right tale thing art away visual flick series fans matter small lives beautiful black run stories men past boy stand obvious home moral girl inside charm rich imagination role looks tries pleasure dumb completely gags period sequences hilarious usual white told truth\n",
      "Topic #5:\n",
      "rrb lrb characters funny work audience cast american emotional ve documentary worth true face idea power mind engaging filmmaking version charming intelligent lack violence melodrama tragedy sad formula adventure complex audiences possible odd fantasy help events novel seeing hip cliches adults given visually living female unexpected blood slightly start appeal\n",
      "Topic #6:\n",
      "film just life make screen big great year acting far moments subject point think looking writer low place john experience light predictable ideas truly message play suspense fresh line wo class sure different dog shows filmmaker memorable somewhat straight running large wrong creepy hold vision view heavy trip felt taste\n",
      "Topic #7:\n",
      "best long heart war watching music lot making going takes piece comic set classic perfect study short social woman thought energy political death opera directed turn written slow scene sort images enjoy beauty historical shot house soap cultural rare college contrived single lost emotionally creative touching approach certain disney flicks\n",
      "Topic #8:\n",
      "plot makes feel better look real minutes human interesting material original style come genre premise trying age level mr effects laughs easy effort book coming strong silly enjoyable exercise intelligence fact nature actor deep talent viewer fails close simple hit difficult days 10 90 crime important artist second passion road\n",
      "Topic #9:\n",
      "like self script actors ll direction familiar need theater children especially hours offers storytelling wit manages recent flat feeling plays jokes supposed sex cool mystery ends psychological attempt beautifully doing parents future british satire weird earnest post excellent potential merely masterpiece guys killer wonder delightful release share hell manner bright\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    \n",
    "print_top_words(lda, vectorizer.get_feature_names(), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=5)\n",
    "boost = AdaBoostClassifier()\n",
    "svc = SVC()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "t0 = time.time()\n",
    "forest_score = cross_val_score(forest, L, subset.Sentiment).mean()\n",
    "print \"Random Forest: %2.2f\" % forest_score\n",
    "print \"dt: %f\" % (time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "boost_score = cross_val_score(boost, L, subset.Sentiment).mean()\n",
    "print \"AdaBoost:      %2.2f\" % boost_score\n",
    "print \"dt: %f\" % (time.time() - t0)\n",
    "\n",
    "t0 = time.time()\n",
    "svc_score = cross_val_score(svc, L, subset.Sentiment).mean()\n",
    "print \"SVC:           %2.2f\" % svc_score\n",
    "print \"dt: %f\" % (time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 2000)\n",
      "(156060, 10)\n",
      "dt: 104.314473\n",
      "(66292, 2000)\n",
      "(66292, 10)\n",
      "dt: 1.638128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "subset = train\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=2, max_df=0.95, max_features=2000)\n",
    "X = vectorizer.fit_transform(subset.Phrase)\n",
    "print X.shape\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=10)\n",
    "\n",
    "t0 = time.time()\n",
    "L = lda.fit_transform(X, subset.Sentiment)\n",
    "print L.shape\n",
    "print \"dt: %f\" % (time.time() - t0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=5)\n",
    "forest.fit(L, subset.Sentiment)\n",
    "\n",
    "subset = test\n",
    "X = vectorizer.transform(subset.Phrase)\n",
    "print X.shape\n",
    "\n",
    "t0 = time.time()\n",
    "L = lda.transform(X)\n",
    "print L.shape\n",
    "print \"dt: %f\" % (time.time() - t0)\n",
    "y = forest.predict(L)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'PhraseId': test.PhraseId,\n",
    "    'Sentiment': y\n",
    "})\n",
    "\n",
    "df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
