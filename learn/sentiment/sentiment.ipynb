{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment using TextBlob\n",
    "\n",
    "This model will simply use TextBlob to determine the sentiment of each phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('../Lemmatization/result_train.csv', encoding='ascii')\n",
    "test = pd.read_csv('../Lemmatization/result_test.csv', encoding='ascii')\n",
    "train.fillna('', inplace=True)\n",
    "test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sentiments\n",
    "\n",
    "We'll calculate sentiments TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def text_blob_sentiment(phrase):\n",
    "    try:\n",
    "        return TextBlob(phrase).sentiment.polarity\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_text_blob_sentiments(phrases):\n",
    "    sentiments = map(text_blob_sentiment, phrases)\n",
    "    return pd.DataFrame({'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data\n",
    "\n",
    "We will split the training data into two parts. The first of these parts will be used to train the model, and the other will be used to make predictions. Later on, we will feed these predictions into a higher level learner as a feature. Since we are using labeled data, we can give the ensemble learner the these predictions along with the corresponding true sentiments. This will allow the ensemble learner to fit the predictions to the actual sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_index = int(len(train) / 2)\n",
    "cv = train[:split_index]\n",
    "train = train[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Sentiments with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sent = get_text_blob_sentiments(train.Phrase)\n",
    "X_cv_sent = get_text_blob_sentiments(cv.Phrase)\n",
    "X_test_sent = get_text_blob_sentiments(test.Phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "We can do some cross validation to determine which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest cross validation runnning...\n",
      "Random Forest Score: 0.50\n",
      "dt: 0.410119\n",
      "\n",
      "AdaBoost cross validation runnning...\n",
      "AdaBoost Score:      0.58\n",
      "dt: 0.211438\n",
      "\n",
      "SVC cross validation runnning...\n",
      "SVC Score:           0.69\n",
      "dt: 0.008381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_val(X, y):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    boost = AdaBoostClassifier()\n",
    "    svc = SVC()\n",
    "\n",
    "    from sklearn.cross_validation import cross_val_score\n",
    "    import time\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"Random Forest cross validation runnning...\"\n",
    "    forest_score = cross_val_score(forest, X, y).mean()\n",
    "    print \"Random Forest Score: %2.2f\" % forest_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"AdaBoost cross validation runnning...\"\n",
    "    boost_score = cross_val_score(boost, X, y).mean()\n",
    "    print \"AdaBoost Score:      %2.2f\" % boost_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    print \"SVC cross validation runnning...\"\n",
    "    svc_score = cross_val_score(svc, X, y).mean()\n",
    "    print \"SVC Score:           %2.2f\" % svc_score\n",
    "    print \"dt: %f\" % (time.time() - t0)\n",
    "    print \"\"\n",
    "    \n",
    "cross_val(X_cv_sent, cv.Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVC...\n",
      "predicting...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "print \"training SVC...\"\n",
    "svc.fit(X_train_sent, train.Sentiment)\n",
    "\n",
    "# Predict using cross validation data\n",
    "cv_pred = svc.predict(X_cv_sent)\n",
    "results_cv = pd.DataFrame({\n",
    "    'PhraseId': cv.PhraseId,\n",
    "    'Predicted': cv_pred,\n",
    "    'Sentiment': cv.Sentiment\n",
    "})\n",
    "results_cv.to_csv('results_train.csv', index=False)\n",
    "\n",
    "print \"predicting...\"\n",
    "y_pred = svc.predict(X_test_sent)\n",
    "\n",
    "results_test = pd.DataFrame({\n",
    "    'PhraseId': test.PhraseId,\n",
    "    'Sentiment': y_pred\n",
    "})\n",
    "\n",
    "results_test.to_csv('results_test.csv', index=False)\n",
    "print \"done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kaggle Results\n",
    "\n",
    "![Kaggle Results]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
